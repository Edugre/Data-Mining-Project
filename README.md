### Interactive Supermarket Simulation with Association Rule Mining

#### Authors Information
1. **Name**: Eduardo Goncalvez 
- **Student ID**: 6526311  

2. **Name**: Alex Waisman 
- **Student ID**: 6529880  

3. **Name**: IvÃ¡n Salazar  
- **Student ID**: 6237206  

- **Course**: CAI 4002 - Artificial Intelligence  
- **Semester**: Fall 2025  

---

### System Overview

This project is an interactive supermarket shopping simulator combined with data preprocessing and association rule mining.  
Users create or import transactions, clean the dataset, and run Apriori, Eclat, and Association Rule Generation to discover product relationships and recommendations.

The full application is built as a modern interactive web app using Streamlit.

---

### Technical Stack

- Language: Python 3.10+
- Main Libraries:
  - `pandas` (data handling)
  - `streamlit` (UI)
  - Custom implementations of:
    - Apriori
    - Eclat
    - Association Rule Generator
- UI Framework: Streamlit

---

### Installation

#### Prerequisites
- Python 3.10 or higher

#### Setup
```bash
# Move into project directory
cd assignment_data_mining

# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run src/frontend/app.py
```

---

### Usage

#### 1. Load Data
- Manual Entry: Click product cards to add them to your cart and complete transactions in the `Shopping` tab.
- Import CSV: Upload an external csv or load sample data in the `Data Import` tab.
- View all the transactions in the dataset in the `View Transactions` tab.

#### 2. Preprocess Data
- In the `Data Preprocessing` tab:
    - Click the `ðŸš€ Run Preprocessing` button to use our preprocessing functions.
    - This will:
        - Delete empty transactions.
        - Delete transactions with a single item.
        - Remove duplicate items.
        - Remove items not found in `products.csv`.
        - Standardize item names (lowercase + trimmed).
    - You will be able to see a report & after comparison of the proccessed data. 
    - You can apply the cleaned in the webapp dataset by clicking the `Apply Cleaned Transactions` button.

#### 3. Run Mining
- In the `Association Rules Mining` tab:
    - Set minimum support and minimum confidence.
    - Click the `ðŸš€ Run Mining Algorithms` button to run the Apriori and Eclat algorithms in the current dataset.
    - After running both algorithms the app will display a performance comparison with running times, used memory, and number of rules generated.

#### 4. Query Results
- In the `Association Rules Mining` tab you will be able to select a product under our `ðŸŽ¯ Product Recommendation System`.
- Select a product from the dropdown menu, products with significant associations will contain a checkmark (âœ“) next to them. 
- Products with significant associations will display associated items and their recommendation strength. 
- Optional: View technical details (raw rules, performance metrics) under our `View All Association Rules` tab and by marking the `Show technical details` checkbox.

---

### Algorithm Implementation

#### Apriori
Apriori finds frequent itemsets by exploring them level by level, starting from single items and expanding upward. At each step, it joins frequent (k-1)-itemsets to form candidate k-itemsets, counts their support in the dataset, and removes those that donâ€™t meet the minimum support threshold. This iterative process continues until no more frequent itemsets can be generated.

- Data structure: Dictionary of frozensets mapping itemsets to their support values
- Candidate generation: Breadth-first, level-wise approach where candidates of size k are generated by joining frequent itemsets of size k-1
- Pruning strategy: Minimum support thresholdâ€”itemsets with support below min_support are discarded after each level

#### Eclat
The Eclat algorithm uses a vertical format where each item is represented by the set of transaction IDs that contain it, allowing support to be computed through simple set intersections. It expands itemsets using a depth-first search, recursively intersecting TID-sets to generate larger frequent itemsets without rescanning the entire database. This approach makes Eclat especially efficient on dense datasets where many items commonly co-occur.

- Data structure: TID-set representation using dictionaries mapping items to sets of transaction IDs
- Search strategy: Depth-first recursive exploration of the itemset search space
- Intersection method: Set intersection operations on TID-sets to compute support and generate new itemsets

#### Association Rule Generation
- For each frequent itemset:
  - Generates subsets  
  - Computes:
    - Support  
    - Confidence  
    - Lift  
- Keeps rules meeting the minimum confidence threshold.

---

### Performance Results

Tested using the cleaned sample dataset (~80â€“100 transactions):

| Algorithm | Runtime (ms) | Rules Generated | Memory Usage |
|-----------|--------------|-------------------|-----------------|
| Apriori   | ~1.55 ms    | 11            | 0.008 MB        |
| Eclat     | ~0.55 ms    | 11            | 0.011 MB        |

**Parameters used**:  
`min_support = 0.2`  
`min_confidence = 0.5`

---

### Project Structure

```
project-root/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ apriori.py
â”‚   â”‚   â”œâ”€â”€ eclat.py
â”‚   â”‚   â”œâ”€â”€ performance_comparison.py
â”‚   â”‚   â””â”€â”€ association_rules.py
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ preprocessing_utils.py
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚    â”œâ”€â”€ data_import.py
â”‚       â”‚    â”œâ”€â”€ home.py
â”‚       â”‚    â”œâ”€â”€ mining.py
â”‚       â”‚    â”œâ”€â”€ preprocessing.py
â”‚       â”‚    â”œâ”€â”€ shopping.py
â”‚       â”‚    â””â”€â”€ transactions.py
â”‚       â””â”€â”€ app.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_transactions.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â””â”€â”€ cleaned_transactions.csv
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ REPORT.pdf
```

---

### Data Preprocessing

Issues handled:
- Empty transactions: 5 removed
- Single-item transactions: 6 removed
- Duplicate items: 9 instances cleaned
- Case inconsistencies: Entire dataset standardized
- Invalid items: 7 instances removed
- Extra whitespace: trimmed from all items

---

### Testing

**Verified functionality**
- [x] CSV import and parsing  
- [x] Preprocessing operations  
- [x] Apriori implementation  
- [x] Eclat implementation  
- [x] Association rule generation  
- [x] Recommendation interface  

**Test cases include**
- [x] Duplicate detection  
- [x] Invalid-product removal  
- [x] Support/confidence threshold changes  
- [x] Recommendation accuracy  

---

### Known Limitations

- CLOSET algorithm not implemented.
- UI performance depends on Streamlit session state.

---

### AI Tool Usage

This project used ChatGPT for step-by-step guidance in understanding the Apriori and Eclat algorithms and for assistance in drafting documentation. Claude Code was used to help debug certain implementation issues and suggest Streamlit UI components.

All AI-assisted code was reviewed, rewritten where needed, and thoroughly tested to ensure full compliance with the assignment requirements.

---

### References

- Course lecture material (Association Rule Mining)
- Apriori and Eclat algorithm descriptions  
- Streamlit documentation  
- Pandas documentation  
